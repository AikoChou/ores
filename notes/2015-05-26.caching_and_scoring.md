# Caching and Scores
*2015-05-26 -- halfak*

In this set of notes, I want to think better about what revscoring's scorer API *should* look like -- so that we can implement a robust caching and distributed processing strategy without a bunch of hacks.

So here's the general flow of a score request that I think we need to handle:
1. Check that the request is well formed and that the requested models *exist*
2. Look up (wiki, model, rev_id) currently being processed by celery and get a set of `AsyncResult`s to hold onto.
3. Look up (wiki, model, rev_id) in the cache
4. Filter for (wiki, model, rev_id) that aren't already accounted for and register that we're currently in the process of processing them.
5. Pre-load `Datasource`s for these missing scores into a map
6. Pass pre-loaded data to celery for processing and obtain a new set of `AsyncResult`s
7. Post-process cached scores and `AsyncResult`s into score map and return it.  

## The status of things

We have a `ScorerModel` that implements *features --> score*.  We have a `Scorer` that combines an `Extractor` with a set of `ScorerModel`s.  It implements *rev_ids --> scores*

While wrapping up `Scorer`, we make the library easy to work with in the simple case, we construct barriers to our ability to follow the efficient pattern discussed above.

One strong motivator to having a set of `ScorerModel` wrapped by a `Scorer` is that it allows us to take advantage of `Feature` overlap in the `ScorerModels` when applying more than one model to the data.  While we have only stood one model up in the system so far, we've written our ORES API to explicitly handle this.

## Proposed changes

Let us kill the multi-model optimization.  I think it is clearly premature.  We can always come back to it later if we find that we'll get an appropriate benefit for the complexity it adds.  This means we ought to change our URL structure.

* **old:** `ores.labs/<wiki>/?models=<model>...&revids=<revid>...`
* **new:** `ores.labs/<wiki>/<model>/?revids=<revid>...`

This will simplify the way that we pre-cache `Datasource`s and look things up in the cache.  

We should also probably kill `Scorer` and just pair `ScorerModel` with `Extractor`.

Finally, I think that we should implement a different sort of `ScOREr` (or some cute name like that) that is *not* part of WSGI, but rather something that is used by the WSGI routes.  This will substantially reduce code that sits in routes and simplify our config.
